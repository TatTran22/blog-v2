---
title: 'Linear Regression (Hồi quy tuyến tính)'
date: '2023-09-23 15:00:00 +0700'
tags: ['machine learning', 'linear regression']
draft: false
summary: 'Hồi quy tuyến tính là một trong những kỹ thuật thống kê đơn giản và được sử dụng rộng rãi nhất trong học máy. Đây là một cách tiếp cận tuyến tính để mô hình hóa mối quan hệ giữa một biến phản hồi vô hướng (hoặc biến phụ thuộc) và một hoặc nhiều biến giải thích (hoặc biến độc lập).'
---

**Hồi quy tuyến tính** là một trong những kỹ thuật thống kê đơn giản và được sử dụng rộng rãi nhất trong học máy. Đây là một cách tiếp cận tuyến tính để mô hình hóa mối quan hệ giữa một biến phản hồi vô hướng (hoặc biến phụ thuộc) và một hoặc nhiều biến giải thích (hoặc biến độc lập).

## Ý tưởng cơ bản:

Hãy tưởng tượng bạn có các điểm dữ liệu trên một mặt phẳng 2D và bạn muốn vẽ một đường thẳng mô tả tốt nhất mối quan hệ giữa các giá trị trục x và trục y. Đường thẳng đó chính là "mô hình tuyến tính" mà bạn đang cố tìm. Mục tiêu chính là giảm thiểu khoảng cách (thường là khoảng cách bình phương) từ các điểm đến đường thẳng, làm cho nó phù hợp nhất.

## Công thức Toán học:

Mô hình hồi quy tuyến tính đơn giản là:

$$
y = \beta_0 + \beta_1 x + \epsilon
$$

Trong đó:

- $y$ là biến phụ thuộc.
- $x$ là biến độc lập.
- $\beta_0$ là điểm cắt trục y.
- $\beta_1$ là độ dốc của đường thẳng.
- $\epsilon$ đại diện cho sai số (sự khác biệt giữa giá trị quan sát và dự đoán).

Đối với hồi quy tuyến tính nhiều biến, khi bạn có nhiều hơn một biến độc lập, phương trình mở rộng thành:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p + \epsilon
$$

## Phương pháp Bình phương nhỏ nhất:

Phương pháp phổ biến nhất để xác định các hệ số \( \beta_0 \) và \( \beta_1 \) là phương pháp bình phương nhỏ nhất. Phương pháp này nhằm giảm thiểu tổng các sai số bình phương:

$$
RSS = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2
$$

## Giả định của Hồi quy Tuyến tính:

1. **Tính tuyến tính:** Mối quan hệ giữa biến độc lập và biến phụ thuộc là tuyến tính.
2. **Độc lập:** Các sai số là độc lập, tức là không có sự tương quan giữa các sai số liên tiếp.
3. **Đồng biến độ:** Biến độ hằng số của sai số qua tất cả các mức của biến độc lập.
4. **Tính chuẩn:** Đối với bất kỳ giá trị cố định nào của biến độc lập, biến phụ thuộc tuân theo phân phối chuẩn.
5. **Không đa cộng tuyến:** Trong trường hợp nhiều biến độc lập, chúng không nên có mối tương quan mạnh mẽ với nhau.

## Ưu và nhược điểm:

**Ưu điểm:**

- Dễ hiểu và giải thích.
- Nhanh chóng để mô hình và dự đoán.
- Phục vụ như một mô hình cơ sở tốt.

**Nhược điểm:**

- Giả định mối quan hệ tuyến tính giữa các biến.
- Có thể nhạy cảm với ngoại lệ.
- Không nắm bắt tốt mối quan hệ phức tạp.

## Triển khai bằng Python (sử dụng `sklearn`):

```python
from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression
import matplotlib.pyplot as plt

# Tạo dữ liệu ngẫu nhiên
X, y = make_regression(n_samples=100, n_features=1, noise=15, random_state=42)

# Tạo và huấn luyện mô hình
model = LinearRegression().fit(X, y)

# Dự đoán giá trị
y_pred = model.predict(X)

# Vẽ biểu đồ
plt.scatter(X, y, color='blue')
plt.plot(X, y_pred, color='red')
plt.show()

```
